# NeuralNetFromScratch

This project implements a neural network from scratch using Python, without relying on high-level libraries like TensorFlow or PyTorch. The goal is to understand the core principles of neural networks by building one manually.

## Features

- Fully connected neural network implementation
- Support for multiple layers and activation functions
- Forward and backward propagation
- Gradient descent optimization
- Customizable architecture and hyperparameters

## Prerequisites

- Python 3.6 or later
- Required libraries:
  - `numpy`
  - `pandas`
  - `matplotlib` (optional, for visualization)

You can install the required libraries using:

```bash
pip install numpy pandas matplotlib
```

## Usage

1. Clone the repository and navigate to the project directory:

```bash
git clone <repository-url>
cd <repository-directory>
```

2. Open the Jupyter Notebook `neuralnetfromscratch.ipynb`:

```bash
jupyter notebook neuralnetfromscratch.ipynb
```

3. Run the notebook cells sequentially to:
   - Initialize the neural network
   - Train it on sample data
   - Visualize the results (add your own code)

## Project Structure

- `neuralnetfromscratch.ipynb`: Main notebook containing the implementation and example usage of the neural network.

## Key Concepts Covered

- Neural network architecture
- Activation functions (e.g., sigmoid, ReLU)
- Loss functions
- Backpropagation algorithm
- Gradient descent optimization

## Acknowledgments

This project is for educational purposes and aims to provide an in-depth understanding of the workings of neural networks by building one from the ground up.
